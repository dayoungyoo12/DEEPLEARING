{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib3\n",
    "import zipfile\n",
    "import shutil\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "http = urllib3.PoolManager()\n",
    "url ='http://www.manythings.org/anki/fra-eng.zip'\n",
    "filename = 'fra-eng.zip'\n",
    "path = os.getcwd()\n",
    "zipfilename = os.path.join(path, filename)\n",
    "with http.request('GET', url, preload_content=False) as r, open(zipfilename, 'wb') as out_file:       \n",
    "    shutil.copyfileobj(r, out_file)\n",
    "\n",
    "with zipfile.ZipFile(zipfilename, 'r') as zip_ref:\n",
    "    zip_ref.extractall(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185583"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 불러오기 및 데이터 길이\n",
    "lines = pd.read_csv('fra.txt', names=['src', 'tar', 'lic'], sep='\\t')\n",
    "del lines['lic']\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>No problem.</td>\n",
       "      <td>Aucun problème.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25497</th>\n",
       "      <td>We went due north.</td>\n",
       "      <td>Nous partîmes plein nord.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22370</th>\n",
       "      <td>I don't want that.</td>\n",
       "      <td>Je ne veux pas de ça !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36019</th>\n",
       "      <td>The concert is over.</td>\n",
       "      <td>Le concert est fini.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43626</th>\n",
       "      <td>We walked to my room.</td>\n",
       "      <td>Nous avons marché jusqu'à ma chambre.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27533</th>\n",
       "      <td>Help me if you can.</td>\n",
       "      <td>Aide-moi, si tu le peux !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35737</th>\n",
       "      <td>Somebody intervened.</td>\n",
       "      <td>Quelqu'un intervint.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35738</th>\n",
       "      <td>Somebody killed Tom.</td>\n",
       "      <td>Quelqu'un a tué Tom.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45380</th>\n",
       "      <td>Don't be so impatient.</td>\n",
       "      <td>Ne sois pas si impatient !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53521</th>\n",
       "      <td>I just heard something.</td>\n",
       "      <td>Je viens d'entendre quelque chose.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           src                                    tar\n",
       "2191               No problem.                        Aucun problème.\n",
       "25497       We went due north.              Nous partîmes plein nord.\n",
       "22370       I don't want that.                 Je ne veux pas de ça !\n",
       "36019     The concert is over.                   Le concert est fini.\n",
       "43626    We walked to my room.  Nous avons marché jusqu'à ma chambre.\n",
       "27533      Help me if you can.              Aide-moi, si tu le peux !\n",
       "35737     Somebody intervened.                   Quelqu'un intervint.\n",
       "35738     Somebody killed Tom.                   Quelqu'un a tué Tom.\n",
       "45380   Don't be so impatient.             Ne sois pas si impatient !\n",
       "53521  I just heard something.     Je viens d'entendre quelque chose."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 샘플데이터 저장\n",
    "lines = lines.loc[:, 'src':'tar']\n",
    "lines = lines[0:60000] \n",
    "lines.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26220</th>\n",
       "      <td>You were charming.</td>\n",
       "      <td>\\t Tu as été adorable. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21949</th>\n",
       "      <td>He ruined my life.</td>\n",
       "      <td>\\t Il a ruiné ma vie. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19442</th>\n",
       "      <td>They play soccer.</td>\n",
       "      <td>\\t Ils jouent au foot. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37180</th>\n",
       "      <td>We're among friends.</td>\n",
       "      <td>\\t Nous sommes au milieu d'amis. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23903</th>\n",
       "      <td>No one trusts Tom.</td>\n",
       "      <td>\\t Personne ne fait confiance à Tom. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>Join us.</td>\n",
       "      <td>\\t Joignez-vous à nous. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24574</th>\n",
       "      <td>They are very big.</td>\n",
       "      <td>\\t Elles sont très massives. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39864</th>\n",
       "      <td>I don't want to stay.</td>\n",
       "      <td>\\t Je ne veux pas rester. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11026</th>\n",
       "      <td>That was a lie.</td>\n",
       "      <td>\\t C'était un mensonge. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56561</th>\n",
       "      <td>Tom could speak French.</td>\n",
       "      <td>\\t Tom peut parler français. \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           src                                      tar\n",
       "26220       You were charming.                \\t Tu as été adorable. \\n\n",
       "21949       He ruined my life.                 \\t Il a ruiné ma vie. \\n\n",
       "19442        They play soccer.                \\t Ils jouent au foot. \\n\n",
       "37180     We're among friends.      \\t Nous sommes au milieu d'amis. \\n\n",
       "23903       No one trusts Tom.  \\t Personne ne fait confiance à Tom. \\n\n",
       "327                   Join us.               \\t Joignez-vous à nous. \\n\n",
       "24574       They are very big.          \\t Elles sont très massives. \\n\n",
       "39864    I don't want to stay.             \\t Je ne veux pas rester. \\n\n",
       "11026          That was a lie.               \\t C'était un mensonge. \\n\n",
       "56561  Tom could speak French.          \\t Tom peut parler français. \\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.tar = lines.tar.apply(lambda x : '\\t '+ x + ' \\n')\n",
    "lines.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 글자 집합 구축\n",
    "src_vocab=set()\n",
    "for line in lines.src: \n",
    "    for char in line: \n",
    "        src_vocab.add(char)\n",
    "\n",
    "tar_vocab=set()\n",
    "for line in lines.tar:\n",
    "    for char in line:\n",
    "        tar_vocab.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n",
      "105\n"
     ]
    }
   ],
   "source": [
    "src_vocab_size = len(src_vocab)+1\n",
    "tar_vocab_size = len(tar_vocab)+1\n",
    "print(src_vocab_size)\n",
    "print(tar_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "['T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w']\n"
     ]
    }
   ],
   "source": [
    "src_vocab = sorted(list(src_vocab))\n",
    "tar_vocab = sorted(list(tar_vocab))\n",
    "print(src_vocab[45:75])\n",
    "print(tar_vocab[45:75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 1, '!': 2, '\"': 3, '$': 4, '%': 5, '&': 6, \"'\": 7, ',': 8, '-': 9, '.': 10, '/': 11, '0': 12, '1': 13, '2': 14, '3': 15, '4': 16, '5': 17, '6': 18, '7': 19, '8': 20, '9': 21, ':': 22, '?': 23, 'A': 24, 'B': 25, 'C': 26, 'D': 27, 'E': 28, 'F': 29, 'G': 30, 'H': 31, 'I': 32, 'J': 33, 'K': 34, 'L': 35, 'M': 36, 'N': 37, 'O': 38, 'P': 39, 'Q': 40, 'R': 41, 'S': 42, 'T': 43, 'U': 44, 'V': 45, 'W': 46, 'X': 47, 'Y': 48, 'Z': 49, 'a': 50, 'b': 51, 'c': 52, 'd': 53, 'e': 54, 'f': 55, 'g': 56, 'h': 57, 'i': 58, 'j': 59, 'k': 60, 'l': 61, 'm': 62, 'n': 63, 'o': 64, 'p': 65, 'q': 66, 'r': 67, 's': 68, 't': 69, 'u': 70, 'v': 71, 'w': 72, 'x': 73, 'y': 74, 'z': 75, 'é': 76, '’': 77, '€': 78}\n",
      "{'\\t': 1, '\\n': 2, ' ': 3, '!': 4, '\"': 5, '$': 6, '%': 7, '&': 8, \"'\": 9, '(': 10, ')': 11, ',': 12, '-': 13, '.': 14, '0': 15, '1': 16, '2': 17, '3': 18, '4': 19, '5': 20, '6': 21, '7': 22, '8': 23, '9': 24, ':': 25, '?': 26, 'A': 27, 'B': 28, 'C': 29, 'D': 30, 'E': 31, 'F': 32, 'G': 33, 'H': 34, 'I': 35, 'J': 36, 'K': 37, 'L': 38, 'M': 39, 'N': 40, 'O': 41, 'P': 42, 'Q': 43, 'R': 44, 'S': 45, 'T': 46, 'U': 47, 'V': 48, 'W': 49, 'X': 50, 'Y': 51, 'Z': 52, 'a': 53, 'b': 54, 'c': 55, 'd': 56, 'e': 57, 'f': 58, 'g': 59, 'h': 60, 'i': 61, 'j': 62, 'k': 63, 'l': 64, 'm': 65, 'n': 66, 'o': 67, 'p': 68, 'q': 69, 'r': 70, 's': 71, 't': 72, 'u': 73, 'v': 74, 'w': 75, 'x': 76, 'y': 77, 'z': 78, '\\xa0': 79, '«': 80, '»': 81, 'À': 82, 'Ç': 83, 'É': 84, 'Ê': 85, 'Ô': 86, 'à': 87, 'â': 88, 'ç': 89, 'è': 90, 'é': 91, 'ê': 92, 'ë': 93, 'î': 94, 'ï': 95, 'ô': 96, 'ù': 97, 'û': 98, 'œ': 99, '\\u2009': 100, '\\u200b': 101, '‘': 102, '’': 103, '\\u202f': 104}\n"
     ]
    }
   ],
   "source": [
    "# 정수인코딩\n",
    "src_to_index = dict([(word, i+1) for i, word in enumerate(src_vocab)])\n",
    "tar_to_index = dict([(word, i+1) for i, word in enumerate(tar_vocab)])\n",
    "print(src_to_index)\n",
    "print(tar_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30, 64, 10], [30, 64, 10], [30, 64, 10], [31, 58, 10], [31, 58, 10]]\n"
     ]
    }
   ],
   "source": [
    "encoder_input = []\n",
    "for line in lines.src:\n",
    "    temp_X = []\n",
    "    for w in line: \n",
    "      temp_X.append(src_to_index[w])\n",
    "    encoder_input.append(temp_X)\n",
    "print(encoder_input[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3, 48, 53, 3, 4, 3, 2], [1, 3, 39, 53, 70, 55, 60, 57, 14, 3, 2], [1, 3, 28, 67, 73, 59, 57, 3, 4, 3, 2], [1, 3, 45, 53, 64, 73, 72, 3, 4, 3, 2], [1, 3, 45, 53, 64, 73, 72, 14, 3, 2]]\n"
     ]
    }
   ],
   "source": [
    "decoder_input = []\n",
    "for line in lines.tar:\n",
    "    temp_X = []\n",
    "    for w in line:\n",
    "      temp_X.append(tar_to_index[w])\n",
    "    decoder_input.append(temp_X)\n",
    "print(decoder_input[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 48, 53, 3, 4, 3, 2], [3, 39, 53, 70, 55, 60, 57, 14, 3, 2], [3, 28, 67, 73, 59, 57, 3, 4, 3, 2], [3, 45, 53, 64, 73, 72, 3, 4, 3, 2], [3, 45, 53, 64, 73, 72, 14, 3, 2]]\n"
     ]
    }
   ],
   "source": [
    "decoder_target = []\n",
    "for line in lines.tar:\n",
    "    t=0\n",
    "    temp_X = []\n",
    "    for w in line:\n",
    "      if t>0:\n",
    "        temp_X.append(tar_to_index[w])\n",
    "      t=t+1\n",
    "    decoder_target.append(temp_X)\n",
    "print(decoder_target[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "76\n"
     ]
    }
   ],
   "source": [
    "max_src_len = max([len(line) for line in lines.src])\n",
    "max_tar_len = max([len(line) for line in lines.tar])\n",
    "print(max_src_len)\n",
    "print(max_tar_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패딩\n",
    "encoder_input = pad_sequences(encoder_input, maxlen=max_src_len, padding='post')\n",
    "decoder_input = pad_sequences(decoder_input, maxlen=max_tar_len, padding='post')\n",
    "decoder_target = pad_sequences(decoder_target, maxlen=max_tar_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = to_categorical(encoder_input)\n",
    "decoder_input = to_categorical(decoder_input)\n",
    "decoder_target = to_categorical(decoder_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(None, src_vocab_size))\n",
    "encoder_lstm = LSTM(units=256, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None, tar_vocab_size))\n",
    "decoder_lstm = LSTM(units=256, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _= decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_softmax_layer = Dense(tar_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "750/750 [==============================] - 231s 305ms/step - loss: 0.7517 - val_loss: 0.6730\n",
      "Epoch 2/3\n",
      "750/750 [==============================] - 247s 329ms/step - loss: 0.4652 - val_loss: 0.5396\n",
      "Epoch 3/3\n",
      "750/750 [==============================] - 247s 330ms/step - loss: 0.3866 - val_loss: 0.4781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dace7f7f40>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 훈련\n",
    "model.fit(x=[encoder_input, decoder_input], y=decoder_target, batch_size=64, epochs=3, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(inputs=encoder_inputs, outputs=encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(256,))\n",
    "decoder_state_input_c = Input(shape=(256,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_src = dict((i, char) for char, i in src_to_index.items())\n",
    "index_to_tar = dict((i, char) for char, i in tar_to_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # <SOS>에 해당하는 원-핫 벡터 생성\n",
    "    target_seq = np.zeros((1, 1, tar_vocab_size))\n",
    "    target_seq[0, 0, tar_to_index['\\t']] = 1.\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "\n",
    "    # stop_condition이 True가 될 때까지 루프 반복\n",
    "    while not stop_condition:\n",
    "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # 예측 결과를 문자로 변환\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = index_to_tar[sampled_token_index]\n",
    "\n",
    "        # 현재 시점의 예측 문자를 예측 문장에 추가\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_tar_len):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
    "        target_seq = np.zeros((1, 1, tar_vocab_size))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines=pd.read.csv(\"harryporter.txt\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "입력 문장: Run!\n",
      "정답 문장:  Cours ! \n",
      "번역기가 번역한 문장:  Sois pas ! \n",
      "-----------------------------------\n",
      "입력 문장: Run.\n",
      "정답 문장:  Fuyons ! \n",
      "번역기가 번역한 문장:  Restez votre chante. \n",
      "-----------------------------------\n",
      "입력 문장: Wait!\n",
      "정답 문장:  Attends ! \n",
      "번역기가 번역한 문장:  Soyez pas ! \n",
      "-----------------------------------\n",
      "입력 문장: Go on.\n",
      "정답 문장:  Continuez. \n",
      "번역기가 번역한 문장:  Arrête ! \n",
      "-----------------------------------\n",
      "입력 문장: Oh no!\n",
      "정답 문장:  Oh non ! \n",
      "번역기가 번역한 문장:  Essaie de maintenant. \n"
     ]
    }
   ],
   "source": [
    "for seq_index in [10,20,30,40,50]: # 입력 문장의 인덱스\n",
    "    input_seq = encoder_input[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(35 * \"-\")\n",
    "    print('입력 문장:', lines.src[seq_index])\n",
    "    print('정답 문장:', lines.tar[seq_index][1:len(lines.tar[seq_index])-1]) # '\\t'와 '\\n'을 빼고 출력\n",
    "    print('번역기가 번역한 문장:', decoded_sentence[:len(decoded_sentence)-1]) # '\\n'을 빼고 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
